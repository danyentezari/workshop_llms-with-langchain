{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain\n",
        "\n",
        "ChatGPT, Custom Corpora, and Chat History"
      ],
      "metadata": {
        "id": "sY_Kye_JjtHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1) Environment Setup"
      ],
      "metadata": {
        "id": "R78QKIUg56gq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-3HN9QzjiVZ"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install chromadb\n",
        "!pip install tiktoken\n",
        "\n",
        "# Install package\n",
        "!pip install \"unstructured[all-docs]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC8fBTmGZMZG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "# VectorstoreIndexCreator\n",
        "# Def: Indexes are lookup data structures for looking up\n",
        "# words within documents\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "\n",
        "# Vectorstore\n",
        "# Def: Vectors are embeddings (or numerical representations) of words\n",
        "# within documents.\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# RecursiveCharacterTextSplitter\n",
        "# Def: A text splitter is used to split larger text documents\n",
        "# into batches to make it manageable to process by the OS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "\n",
        "# Chat Memory\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "\n",
        "# Instructions for ChatGPT\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "ttSCO0yikQ-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) Basic Example with Unstructured"
      ],
      "metadata": {
        "id": "D3c4med-5x10"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lNNSxXjwlalF"
      },
      "outputs": [],
      "source": [
        "# Loading a single document\n",
        "# loader = UnstructFileLoader(\"./mathematical_notation.md\")\n",
        "# docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "nJgDDgv0Ylw_"
      },
      "outputs": [],
      "source": [
        "# Loading multiple documents\n",
        "loader = DirectoryLoader('./', glob=\"*.md\")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "6TM7el4Kmh2h",
        "outputId": "99ee7e76-1620-4594-b1c7-0ea7f61bdffc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Measures of Central Tendency\\n\\nThe measures of central tendency are numbers that represent the location of averages in the data.\\n\\nThe measures of central tendency are mean, median, and mode; they are calculated as follows:\\n\\nConsider this set of values\\n\\n$$X = { 3,3,3,4,6,8,8,9 } $$\\n\\nThen, the measures are found as follows,\\n\\nMedian\\n\\nThe number right in the center of $X$. Since there are an even number of values in $X$, we take the two number in the middle and take their average.\\n\\nmedian $= \\\\dfrac{4+6}{2} = 5$\\n\\nMode\\n\\nThe most recurring number in $X$.\\n\\nmode = $3$\\n\\nMean\\n\\nThe mean is used to determine an absolute number by which to compare all other values in the data, With the mean, we can determine both (1) whether some value is above or below the average and (2) the degree of variation in the data.\\n\\nMean is related to variance (and standard deviation) which is covered in its own section\\n\\nTo calculate the mean average of $X$, sum all the values of $X$ and divide this sum by the number of values in $X$.\\n\\nmean = $ \\\\dfrac{3+3+3+4+6+8+8+9}{8} = 5.5$'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Preview an example document\n",
        "docs[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "N3IQPS7DpKhx"
      },
      "outputs": [],
      "source": [
        "# Note:\n",
        "# LangChain by default uses ChromaDB\n",
        "index = VectorstoreIndexCreator().from_loaders([loader])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Nk4e4rpIBTbw"
      },
      "outputs": [],
      "source": [
        "# index.query(\"How is a set written mathamticaly?\")\n",
        "# index.query(\"What is abstract algebra? \")\n",
        "# index.query(\"What's the best way to learn probability theory?\")\n",
        "# index.query(\"Central tendncy vs dispersion?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (3) Fallback to ChatGPT"
      ],
      "metadata": {
        "id": "XzXPEMDBkSLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
      ],
      "metadata": {
        "id": "toTF4eA6lq0Q"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"If the context is not relevant,\n",
        "please answer the question by using your own knowledge about the topic\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "QA_PROMPT = PromptTemplate.from_template(\n",
        "    template=prompt_template\n",
        ")\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True,\n",
        "    output_key='answer'\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=vectorstore.as_retriever(), #index.vectorstore.as_retriever()\n",
        "    chain_type_kwargs={\"prompt\": QA_PROMPT}\n",
        ")"
      ],
      "metadata": {
        "id": "f6Sz9vyRWKLk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain({\n",
        "    \"query\": \"What is a set?\"\n",
        "})"
      ],
      "metadata": {
        "id": "JKPCIE20fEU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a108d908-e984-4c24-efad-45c5d1810434"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'What is a set?',\n",
              " 'result': 'A set is a collection of distinct objects, called elements, that are grouped together based on a common characteristic or property. Sets are often represented by listing their elements inside curly braces, such as {1, 2, 3}, where 1, 2, and 3 are the elements of the set. Sets can be finite or infinite, and the elements can be numbers, letters, or any other type of object. The concept of sets is fundamental in mathematics and is used in various branches, such as set theory, algebra, and calculus.'}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (4) Chat History"
      ],
      "metadata": {
        "id": "UQD1EQR29JYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
      ],
      "metadata": {
        "id": "YsQt4PCQ44h3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"If the context is not relevant,\n",
        "please answer the question by using your own knowledge about the topic\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "QA_PROMPT = PromptTemplate.from_template(\n",
        "    template=prompt_template\n",
        ")\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "chat = ConversationalRetrievalChain.from_llm(\n",
        "    llm,\n",
        "    retriever=vectorstore.as_retriever(),\n",
        "    memory=memory,\n",
        "    combine_docs_chain_kwargs={\"prompt\": QA_PROMPT}\n",
        ")"
      ],
      "metadata": {
        "id": "_IhKtKTknU_O"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chat({\n",
        "#       \"question\": \"What is a set?\"\n",
        "# })"
      ],
      "metadata": {
        "id": "3Gg_eaY53Ghg"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chat({\n",
        "#       \"question\": \"What is brownian motion?\"\n",
        "# })"
      ],
      "metadata": {
        "id": "_QpiqrhAy7jC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chat({\n",
        "#       \"question\": \"So what's a set?\"\n",
        "# })"
      ],
      "metadata": {
        "id": "M55tMVO255M2"
      },
      "execution_count": 32,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}